{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The project will investigate I94 immigration data, world temperature data, and US infographic data and try to provide insights.  \n",
    "\n",
    "In this project, the plan is to assess the data and formulate possible statistics that can be derived.  The data is cleaned and catered towards deriving useful data.  A list of the possible immigration statistics is as follows:\n",
    "- Immigration by city\n",
    "- Age of immigrants \n",
    "- Gender of immigrants\n",
    "- Reason for travel and visa type\n",
    "- Length of stay \n",
    "- Mode of travel\n",
    "- Temperature of cities immigrated to \n",
    "- Country of origin\n",
    "\n",
    "The tools that will be used for the project are as follows:\n",
    "- Python / Pandas\n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "The data that is going to be used is as follows:\n",
    "- **I94 Immigration Data:** The data is provided by the US National Tourism and Trade Office.  The site that provides the data can be found [HERE](https://travel.trade.gov/research/reports/i94/historical/2016.html)\n",
    "- **World Temperature Data:** This data comes from Kaggle and more information can be found [HERE](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)\n",
    "- **US City Demographic Data:** This data comes from OpenSoft and more information can be found [HERE](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)\n",
    "- **Airport Code Table:** This is a table of airport codes with the corresponding cities they are located in and more information can be found [HERE](https://datahub.io/core/airport-codes#data)\n",
    "- **I94 SAS Labels Descriptions:**  This data is derived from a provided SAS file and several tables are created to supplement the above data:\n",
    "    - Country code conversions\n",
    "    - Port code conversions\n",
    "    - Mode of travel conversions\n",
    "    - State code conversions\n",
    "    - Visa type conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import calendar\n",
    "\n",
    "pd.set_option('display.max_rows', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **I94 Immigration Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df = pd.read_sas('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat', 'sas7bdat', encoding='ISO-8859-1')\n",
    "print(len(i94_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Display data types\n",
    "\n",
    "display(i94_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### **Data Analysis**\n",
    "\n",
    "Upon inspection of the data, I am making the following assumptions:\n",
    "- According to the SAS Label Descriptions that correspond to this data, it states that many of the columns are not used by the CIC, so they will be omitted from the data model\n",
    "- The arrdate and depdate columns will need to be converted to readable date types\n",
    "- The isnum column contains many nulls and will likely not be used as a dependable \n",
    "- The first column is not named, but assuming it is a type of record ID.  \n",
    "- Many of the data types are floats when they could be integers (year, month, etc)\n",
    "\n",
    "#### **Data Cleaning**\n",
    "- Columns that are not going to be used will be omitted from the data model\n",
    "- The cicid column will be used as the primary key as a duplicate check has indicated that there are only unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### **immigration_data_sample.csv**\n",
    "| Column                   | Description                                | Used in Dim Table |\n",
    "| -----------------------  | ------------------------------------------ | :---------------: |\n",
    "| cicid (float)            | Immigrant identifier                       |        X          |\n",
    "| i94yr (float)            | 4 digit year                               |        X          |\n",
    "| i94mon (float)           | Numeric month                              |        X          |\n",
    "| i94cit (float)           | Resident birth city                        |        X          |\n",
    "| i94res (text)            | Resident origin res                        |        X          |\n",
    "| i94port (float)          | Arrival port                               |        X          |\n",
    "| arrdate (float)          | Arrival date in US                         |        X          |\n",
    "| i94mode (float)          | Mode of travel                             |        X          |\n",
    "| i94addr (text)           | Address state                              |        X          |\n",
    "| depdate (float)          | Date departing from US                     |        X          |\n",
    "| i94bir (float)           | Age of respondent                          |        X          |\n",
    "| i94visa (float)          | Visa code (visa use)                       |        X          |\n",
    "| count (float)            | Used for summarizing statistics            |                   |\n",
    "| dtadfile (int)           | Data dded to files (not used)              |                   |\n",
    "| visapost (text)          | State where visa was issued (not used)     |                   |\n",
    "| occup (text)             | Occupation in US (not used)                |                   |\n",
    "| entdepa (char)           | Arrival flag (not used)                    |                   |\n",
    "| entdepd (char)           | Departure flag (not used)                  |                   |\n",
    "| entdepu (text)           | Update flag (not used)                     |                   |\n",
    "| matflag (char)           | Match flag                                 |                   |\n",
    "| biryear (float)          | 4 digit year of birth                      |                   |\n",
    "| dtaddto (int)            | Data admitted to US (not used)             |                   |\n",
    "| gender (char)            | Sex of non-immigrant                       |        X          |\n",
    "| insnum (int)              | INS Number                                 |                   |\n",
    "| airline (text)           | Airline used to arrive in US               |        X          |\n",
    "| admnum (int)             | Admission number                           |                   |\n",
    "| fltno (text)             | Flight number                              |                   |\n",
    "| visatype (text)          | Class of admission for temp state          |        X          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop columns that will not be used in the data model (see data model)\n",
    "i94_clean = i94_df.drop(columns=['count', 'dtadfile', 'visapost', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'insnum', 'admnum', 'fltno', 'occup'])\n",
    "\n",
    "i94_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check if first column has duplicate records\n",
    "check = i94_clean['cicid'].duplicated().any()\n",
    "\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove records with null values\n",
    "i94_clean = i94_clean.dropna(how='any',axis=0)\n",
    "\n",
    "print(len(i94_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert fields with float to int\n",
    "i94_clean['cicid'] = i94_clean['cicid'].astype(int)\n",
    "i94_clean['i94yr'] = i94_clean['i94yr'].astype(int)\n",
    "i94_clean['i94mon'] = i94_clean['i94mon'].astype(int)\n",
    "i94_clean['i94yr'] = i94_clean['i94yr'].astype(int)\n",
    "i94_clean['i94cit'] = i94_clean['i94cit'].astype(int)\n",
    "i94_clean['i94res'] = i94_clean['i94res'].astype(int)\n",
    "i94_clean['i94bir'] = i94_clean['i94bir'].astype(int)\n",
    "i94_clean['i94visa'] = i94_clean['i94visa'].astype(int)\n",
    "i94_clean['i94mode'] = i94_clean['i94mode'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert arrdate and depdate from float to date\n",
    "\n",
    "i94_clean['arrdate'] = pd.to_datetime(i94_clean['arrdate']).dt.date\n",
    "i94_clean['depdate'] = pd.to_datetime(i94_clean['depdate']).dt.date\n",
    "\n",
    "i94_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **World Temperature Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_temp_df = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "print(len(world_temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_temp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Display data types\n",
    "display(world_temp_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### **Data Analysis**\n",
    "\n",
    "Upon inspection of the data, I am making the following assumptions:\n",
    "- The data has average temps for each month from 1743-2013 from several cities and countries around the world. \n",
    "- Temperatures can be derived for both the immigrant's country of origin as well as for the United States\n",
    "\n",
    "#### **Data Cleaning**\n",
    "- Columns that are not going to be used will be omitted from the data model\n",
    "- The data will be averaged for each country by month - a new column for month will be created\n",
    "- Rows that have null temperature data will be dropped before aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **GlobalLandTemperatureByCity.csv**\n",
    "| Column                             | Description                      | Used in Dim Table |\n",
    "| ---------------------------------  | -------------------------------- | :---------------: |\n",
    "| dt (date)                          | Date temp taken                  |        X          |\n",
    "| avg temperature (float)            | Average temp                     |        X          |\n",
    "| avg temperature uncertainty (float)| Accounts for margin of error     |        X          |\n",
    "| city (text)                        | City                             |        X          |\n",
    "| country (text)                     | Country                          |        X          |\n",
    "| latitude (text)                    | Latitude                         |                   |\n",
    "| longitude (text)                   | Longitude                        |                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop columns that will not be used in the data model (see data model)\n",
    "world_temp_clean = world_temp_df.drop(columns=['Latitude', 'Longitude'])\n",
    "\n",
    "world_temp_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove records with null values\n",
    "world_temp_clean = world_temp_clean.dropna(how='any',axis=0)\n",
    "\n",
    "print(len(world_temp_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create column for month\n",
    "world_temp_clean['Month'] = pd.DatetimeIndex(world_temp_clean['dt']).month\n",
    "world_temp_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate average temps for each city and country by month\n",
    "world_temp_agg = world_temp_clean.groupby(['City','Country', 'Month' ])['AverageTemperature', 'AverageTemperatureUncertainty'].mean().reset_index()\n",
    "\n",
    "world_temp_agg.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **US City Demographic Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_demo_df = pd.read_csv('us-cities-demographics.csv', sep = ';')\n",
    "print(len(us_demo_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_demo_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Display data types\n",
    "display(us_demo_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### **Data Analysis**\n",
    "\n",
    "Upon inspection of the data, I am making the following assumptions:\n",
    "- The data displays basic demographics for various cities in the US\n",
    "\n",
    "#### **Data Cleaning**\n",
    "- Columns that are not going to be used will be omitted from the data model\n",
    "- Columns with float types will be converted to int as appropriate\n",
    "- Rows that have null data will be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **us-cities-demographics.csv**\n",
    "| Column                   | Description                                | Used in Dim Table |\n",
    "| -----------------------  | ------------------------------------------ | :---------------: |\n",
    "| city (text)              | City in US                                 |        X          |\n",
    "| state (text)             | State in US                                |        X          |\n",
    "| median age (float)       | Median age of population                   |        X          |\n",
    "| male population (int)    | Number of males in population              |        X          |\n",
    "| female population (text) | Number of females in population            |        X          |\n",
    "| total population (int)   | Total people in population                 |        X          |\n",
    "| number of veterans (int) | Veterans in population                     |                   |\n",
    "| foreign-born (int)       | Number of immigrants                       |        X          |\n",
    "| avg household size (int) | Average size of household                  |        X          |\n",
    "| state code (text)        | State abbreviation                         |        X          |\n",
    "| race (text)              | Race                                       |                   |\n",
    "| count (int)              | Count of number of race in population      |                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop columns that will not be used in the data model (see data model)\n",
    "us_demo_clean = us_demo_df.drop(columns=['Number of Veterans', 'Race', 'Count'])\n",
    "\n",
    "us_demo_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove records with null values\n",
    "us_demo_clean = us_demo_clean.dropna(how='any',axis=0)\n",
    "\n",
    "print(len(us_demo_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert male and female populations from float to int\n",
    "\n",
    "us_demo_clean['Male Population'] = us_demo_clean['Male Population'].astype(int)\n",
    "us_demo_clean['Female Population'] = us_demo_clean['Female Population'].astype(int)\n",
    "\n",
    "us_demo_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **Airport Code Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df = pd.read_csv('airport-codes_csv.csv')\n",
    "print(len(airport_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Display data types in the columns\n",
    "display(airport_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### **Data Analysis**\n",
    "\n",
    "Upon inspection of the data, I am making the following assumptions:\n",
    "- It looks like parts of the ident codes will match with port in the immigration table, but not exactly\n",
    "- Given the ideas for analysis presented in the scope, I will only consider airports within the US\n",
    "- Need a way to derive the state\n",
    "\n",
    "#### **Data Cleaning**\n",
    "- Columns that are not going to be used will be omitted from the data model\n",
    "- Columns with float types will be converted to int as appropriate\n",
    "- Rows that have null data will be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **airport-codes_csv.csv**\n",
    "| Column                | Description                                   | Used in Dim Table |\n",
    "| --------------------  | --------------------------------------------- | :---------------: |\n",
    "| ident (text)          | Airport identification code                   |        X          |\n",
    "| type (text)           | Type of airport                               |        X          |\n",
    "| name (text)           | Name of airport                               |        X          |\n",
    "| elevation_ft (int)    | Airport elevation                             |                   |\n",
    "| continent (text)      | Continent                                     |                   |\n",
    "| iso_country (text)    | Country                                       |        X          |\n",
    "| iso_region (text)     | Country and region                            |        X          |\n",
    "| municipality (text)   | City                                          |        X          |\n",
    "| gps_code (text)       | GPS Code                                      |                   |\n",
    "| iata_code (text)      | Airport location identifier                   |                   |\n",
    "| local_code (text)     | Airport code                                  |                   |\n",
    "| coordinates (text)    | Coordinates                                   |                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop columns that will not be used in the data model (see data model)\n",
    "airport_clean = airport_df.drop(columns=['elevation_ft', 'continent', 'gps_code', 'iata_code', 'local_code', 'coordinates'])\n",
    "\n",
    "airport_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove rows that are not US\n",
    "airport_clean = airport_clean[airport_clean.iso_country == 'US']\n",
    "print(len(airport_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create state column\n",
    "states = airport_clean['iso_region'].str.split('-', n = 1, expand = True)\n",
    "airport_clean['state'] = states[1]\n",
    "airport_clean = airport_clean.drop(columns=['iso_region'])\n",
    "\n",
    "airport_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **I94_SAS_Labels_Descriptions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Additional csv files were created using the data available in the I94_SAS_Labels_Descriptions.SAS file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# I94 Travel Modes\n",
    "travel_modes_df = pd.read_csv('i94mode.csv')\n",
    "travel_modes_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# I94 Visa Types\n",
    "visa_types_df = pd.read_csv('visa_type.csv')\n",
    "visa_types_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# I94 Ports\n",
    "ports_df = pd.read_csv('i94prtl.csv')\n",
    "ports_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# I94 State Codes\n",
    "states_df = pd.read_csv('i94addrl.csv')\n",
    "states_df = states_df.drop(columns=['Unnamed: 2'])\n",
    "states_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# I94 Countries\n",
    "countries_df = pd.read_csv('i94cntyl.csv')\n",
    "countries_df = countries_df.drop(columns=['Unnamed: 2'])\n",
    "countries_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The model was designed using a star schema because it would be more performant than the snowflake schema as there are less joins to have to work with.\n",
    "\n",
    "![Data Model](data_model.png)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "The steps that will be taken for the data pipeline are as follows:\n",
    "- Setting up a connection to a local Sparkify database\n",
    "- Renaming the columns of the cleaned data frames as appropriate \n",
    "- Loading the data frames into the database\n",
    "- Adding city column to the fact table to help support the star schema\n",
    "- Perform data quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import os\n",
    "import psycopg2\n",
    "from sql_queries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create database\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create sparkify database with UTF8 Encoding\n",
    "cur.execute(\"drop database if exists sparkifydb\")\n",
    "cur.execute(\"create database sparkifydb with encoding 'utf8' template template0\")\n",
    "\n",
    "# close connection to default database\n",
    "conn.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create connection to database\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop existing tables using the drop_table_queries list\n",
    "for query in drop_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create tables using the create_table_queries list\n",
    "for query in create_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate airport_codes\n",
    "airport_codes_data = airport_clean.values\n",
    "airport_codes_data = airport_codes_data.tolist()\n",
    "\n",
    "try:\n",
    "    cur.executemany(airport_codes_table_insert, airport_codes_data)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows Into Airport Codes Table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate global_temps\n",
    "global_temps_data = world_temp_agg.values\n",
    "global_temps_data = global_temps_data.tolist()\n",
    "\n",
    "try:\n",
    "    cur.executemany(global_temps_table_insert, global_temps_data)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows Into Global Temps Table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate us_cities_demographics\n",
    "us_demo_data = us_demo_clean.values\n",
    "us_demo_data = us_demo_data.tolist()\n",
    "\n",
    "try:\n",
    "    cur.executemany(us_cities_demographics_table_insert, us_demo_data)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows Into US Cities Demographics Table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate countries\n",
    "countries_data = countries_df.values\n",
    "countries_data = countries_data.tolist()\n",
    "\n",
    "try:\n",
    "    cur.executemany(countries_table_insert, countries_data)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows Into US Countries Table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate ports\n",
    "ports_data = ports_df.values\n",
    "ports_data = ports_data.tolist()\n",
    "\n",
    "try:\n",
    "    cur.executemany(ports_table_insert, ports_data)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows Into Ports Table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate states\n",
    "states_data = states_df.values\n",
    "states_data = states_data.tolist()\n",
    "\n",
    "try:\n",
    "    cur.executemany(states_table_insert, states_data)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows Into States Table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate travel_modes\n",
    "travel_mode_data = travel_modes_df.values\n",
    "travel_mode_data = travel_mode_data.tolist()\n",
    "\n",
    "try:\n",
    "    cur.executemany(travel_modes_table_insert, travel_mode_data)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows Into Travel Modes Table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate visa_use\n",
    "visa_use_data = visa_types_df.values\n",
    "visa_use_data = visa_use_data.tolist()\n",
    "\n",
    "try:\n",
    "    cur.executemany(visa_use_table_insert, visa_use_data)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows Into Visa Use Table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create city column to augment immigrant table\n",
    "\n",
    "# Join i94_clean and ports_df - inner join so we have city info for every record\n",
    "immigrants = pd.merge(i94_clean, ports_df, how='inner', left_on = 'i94port', right_on = 'code')\n",
    "immigrants = immigrants.drop(columns=['code', 'port'])\n",
    "\n",
    "immigrants.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate immigrant table\n",
    "immigrants_data = immigrants.values\n",
    "immigrants_data = immigrants_data.tolist()\n",
    "\n",
    "try:\n",
    "    cur.executemany(immigrant_table_insert, immigrants)\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows Into Immigrants Table\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def GetTableLength(table):\n",
    "    try:\n",
    "        cur.execute(f'select count(*) from {table}')\n",
    "        airport_table_records = cur.fetchone()\n",
    "        return airport_table_records[0]\n",
    "    except psycopg2.Error as e:\n",
    "        print('Error: Querying airport_codes Table')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def CheckLengths(df_length, table_length):\n",
    "    if df_length == table_length:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Checks to ensure that the number of expected records are inserted into the database tables\n",
    "passed = []\n",
    "failed = []\n",
    "\n",
    "# airport_codes\n",
    "airport_df_length = len(airport_clean)\n",
    "airport_table_records = GetTableLength('airport_codes')\n",
    "\n",
    "match = CheckLengths(airport_df_length, airport_table_records)\n",
    "\n",
    "if match:\n",
    "    passed.append('airport_codes')\n",
    "else:\n",
    "    failed.append('airport_codes')\n",
    "    \n",
    "# global_temps\n",
    "global_temps_length = len(world_temp_agg)\n",
    "global_temps_table_records = GetTableLength('global_temps')\n",
    "\n",
    "match = CheckLengths(global_temps_length, global_temps_table_records)\n",
    "\n",
    "if match:\n",
    "    passed.append('global_temps')\n",
    "else:\n",
    "    failed.append('global_temps')\n",
    "    \n",
    "# us_cities_demographics\n",
    "us_demo_length = len(us_demo_clean)\n",
    "us_demo_table_records = GetTableLength('us_cities_demographics')\n",
    "\n",
    "match = CheckLengths(us_demo_length, us_demo_table_records)\n",
    "\n",
    "if match:\n",
    "    passed.append('us_cities_demographics')\n",
    "else:\n",
    "    failed.append('us_cities_demographics')\n",
    "    \n",
    "# countries\n",
    "countries_length = len(countries_df)\n",
    "countries_table_records = GetTableLength('countries')\n",
    "\n",
    "match = CheckLengths(countries_length, countries_table_records)\n",
    "\n",
    "if match:\n",
    "    passed.append('countries')\n",
    "else:\n",
    "    failed.append('countries')\n",
    "    \n",
    "# ports\n",
    "ports_length = len(ports_df)\n",
    "ports_table_records = GetTableLength('ports')\n",
    "\n",
    "match = CheckLengths(ports_length, ports_table_records)\n",
    "\n",
    "if match:\n",
    "    passed.append('ports')\n",
    "else:\n",
    "    failed.append('ports')\n",
    "    \n",
    "# states\n",
    "states_length = len(states_df)\n",
    "states_table_records = GetTableLength('states')\n",
    "\n",
    "match = CheckLengths(states_length, states_table_records)\n",
    "\n",
    "if match:\n",
    "    passed.append('states')\n",
    "else:\n",
    "    failed.append('states')\n",
    "    \n",
    "# travel_modes\n",
    "travel_modes_length = len(travel_modes_df)\n",
    "travel_modes_table_records = GetTableLength('travel_modes')\n",
    "\n",
    "match = CheckLengths(travel_modes_length, travel_modes_table_records)\n",
    "\n",
    "if match:\n",
    "    passed.append('travel_modes')\n",
    "else:\n",
    "    failed.append('travel_modes')\n",
    "    \n",
    "# visa_use\n",
    "visa_use_length = len(visa_types_df)\n",
    "visa_use_table_records = GetTableLength('visa_use')\n",
    "\n",
    "match = CheckLengths(visa_use_length, visa_use_table_records)\n",
    "\n",
    "if match:\n",
    "    passed.append('visa_use')\n",
    "else:\n",
    "    failed.append('visa_use')\n",
    "    \n",
    "# immgrant\n",
    "immigrants_length = len(immigrants)\n",
    "immigrants_table_records = GetTableLength('immigrants')\n",
    "\n",
    "match = CheckLengths(immigrants_length, immigrants_table_records)\n",
    "\n",
    "if match:\n",
    "    passed.append('immigrants')\n",
    "else:\n",
    "    failed.append('immigrants')\n",
    "\n",
    "print('Tests Passed:')\n",
    "print(passed)\n",
    "print('Tests Failed:')\n",
    "print(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "### *Dimension Tables*\n",
    "\n",
    "#### **airport_codes**\n",
    "| Column                | Description                                   | \n",
    "| --------------------  | --------------------------------------------- | \n",
    "| ident (text)          | Airport identification code                   |\n",
    "| type (text)           | Type of airport                               | \n",
    "| name (text)           | Name of airport                               |\n",
    "| country (text)        | Country                                       |\n",
    "| state (text)          | State                                         | \n",
    "| city (text)           | City                                          | \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "#### **global_temps**\n",
    "| Column                             | Description                      |\n",
    "| ---------------------------------  | -------------------------------- |\n",
    "| city (text)                        | City                             |\n",
    "| country (text)                     | Country                          |\n",
    "| month (int)                        | Month                            |\n",
    "| avg_temperature (float)            | Average temp                     |\n",
    "| avg_temperature_uncertainty (float)| Accounts for margin of error     |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "#### **us_cities_demographics**\n",
    "| Column                   | Description                                |\n",
    "| -----------------------  | ------------------------------------------ |\n",
    "| city (text)              | City in US                                 |\n",
    "| state (text)             | State in US                                |\n",
    "| median_age (float)       | Median age of population                   |\n",
    "| male_population (int)    | Number of males in population              |\n",
    "| female_population (text) | Number of females in population            |\n",
    "| total_population (int)   | Total people in population                 |\n",
    "| foreign_born (int)       | Number of immigrants                       |\n",
    "| avg_household_size (int) | Average size of household                  |\n",
    "| state_code (text)        | State abbreviation                         |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "#### **countries**\n",
    "| Column                             | Description                      |\n",
    "| ---------------------------------  | -------------------------------- |\n",
    "| code (text)                        | Country code                     |\n",
    "| country (text)                     | Country                          |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "#### **ports**\n",
    "| Column                             | Description                      |\n",
    "| ---------------------------------  | -------------------------------- |\n",
    "| code (text)                        | Port code                        |\n",
    "| port (text)                        | Port                             |\n",
    "| city (text)                        | City                             |\n",
    "| state (text)                       | State                            |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "#### **states**\n",
    "| Column                             | Description                      |\n",
    "| ---------------------------------  | -------------------------------- |\n",
    "| code (text)                        | State code                       |\n",
    "| state (text)                       | State                            |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "#### **travel_modes**\n",
    "| Column                             | Description                      |\n",
    "| ---------------------------------  | -------------------------------- |\n",
    "| code (int)                         | Travel code                      |\n",
    "| mode (text)                        | Travel type                      |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "#### **visa_use**\n",
    "| Column                             | Description                      |\n",
    "| ---------------------------------  | -------------------------------- |\n",
    "| code (int)                         | Visa code                        |\n",
    "| visa (text)                        | Visa type                        |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### *Fact Table*\n",
    "\n",
    "#### **immigrant**\n",
    "| Column                   | Description                                |\n",
    "| -----------------------  | ------------------------------------------ |\n",
    "| cicid (int)              | Immigrant identifier                       |\n",
    "| year (int)               | 4 digit year                               |\n",
    "| month (int)              | Numeric month                              |\n",
    "| birth_res (text)         | Resident birth                             |\n",
    "| origin_res (text)        | Resident origin                            |\n",
    "| port (int)               | Arrival port                               |\n",
    "| arrdate (date)           | Arrival date in US                         |\n",
    "| travel_mode (int)        | Mode of travel                             |\n",
    "| res_state (text)         | Resident state                             |\n",
    "| depdate (date)           | Date departing from US                     |\n",
    "| age (int)                | Age of respondent                          |\n",
    "| visa_use (int)           | Visa code (visa use)                       |\n",
    "| gender (char)            | Sex of non-immigrant                       |\n",
    "| airline (text)           | Airline used to arrive in US               |\n",
    "| visa_type (text)         | Class of admission for temp state          |\n",
    "| port_city  (text)        | Arrival city                               |\n",
    "| port_state  (text)       | Arrival state                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### **Overview**\n",
    "\n",
    "In this project, we investigated I94 immigration data, world temperature data, and US infographic data and try to provide insights.  \n",
    "\n",
    "#### **Tools**\n",
    "\n",
    "The primary tool that I utilized for this exercise was python, specifically, the pandas library.  While I could have just as easily used pyspark, for data exploration, especially with the smaller data sets, I just tend to prefer using pandas.  It allowed me the ability to do everything I needed to do:  explore data, clean data, and interact with databases.\n",
    "\n",
    "#### **Data Updates**\n",
    "\n",
    "Since the data use in this project, there was little consideration for data updates.  Processing data updates would require running all of the cells in this notebook again.  In a production-type pipeline, however, it would be possible to keep the data updated in a more automated fashion.\n",
    "\n",
    "#### **Scenarios**\n",
    "\n",
    "**The data is increased by 100x**\n",
    "\n",
    "With a larger dataset, I would leverage more AWS technologies to help to process the data.  I would likely use pyspark and employee a technology that would allow processing to be more performant, such as an AWS Lambda, and AWS EC2, or an AWS EMR Cluster.\n",
    "\n",
    "**The data populates a dashboard that must be updated on a daily basis by 7am every day**\n",
    "\n",
    "In this scenario, I would set up a pipeline that would allow for automated updates such as AirFlow, Glue, or a Lambda with a trigger.  As part of the pipeline, I would use a persistent database such as RDS or Redshift if cost is not a factor.  My first experiment, however, would likely be a Glue Job writing to Athena tables and connecting the dashboard to Athena.\n",
    "\n",
    "**The database needs to be accessed by 100+ people**\n",
    "\n",
    "In the case where several users need to access the database, I would try to find a persistent and performant database that is also cost effective.  I would take one of two routes as far as providing data availability:  spin up a serverless RDS and use IAM to control the users who are looking to access the data, or store the data in Athena and use workgroups and user tokens to allow users to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
